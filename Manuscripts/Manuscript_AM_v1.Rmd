---
title: '**Bayesian statistics for longitudinal studies in biomedical research**'
author: 
- Ariel Mundo^[Department of Biomedical Engineering, University of Arkansas, Fayetteville]
- Timothy J. Muldoon^[Department of Biomedical Engineering, University of Arkansas, Fayetteville]
- John R. Tipton^[Department of Mathematical Sciences, University of Arkansas, Fayetteville]
  
bibliography: refs.bib
output:
  pdf_document: 
    fig_caption: yes
  html_document: default
  css: style.css
  word_document:
    reference_docx: docx_template.docx
mainfont: Times New Roman
link-citations: yes
subtitle: '_Their application and use in biomedical research_'
biblio-style: apalike
---



## Paper outline
<span style="color: red;">\textcolor{red}{The paper Introduction has been updated, proposed sections appear at the end of the document as well as an initial graph.}</span>


## Background

A longitudinal study is defined as that which is designed to repeatedly measure a variable of interest in a group (or groups) of subjects. In biomedical research, this type of study arises when the investigator intends to observe the evolution of the effect of a certain treatment across time, rather than analyzing it at a single time point (a cross-sectional study). Clinical examples of this  approach in biomedical research include studies on breast and neck cancer [@sio2016;@kamstra2015]; in the first case, weekly measurements of skin toxicities in  patients with radiation-induced dermatitis were taken for up to 8 weeks; whereas in the latter mouth opening was assessed at 6,12, 18, 24 and 36 months after radiotherapy (RT). Longitudinal studies have used also to measure tumor response [@roblyer2011;@tank2020;@pavlov2018;@demidov2018], antibody expression [@ritter2001;@roth2017], and cell metabolism [@jones2018;@skala2010]. From a statistical standpoint, a longitudinal study presents advantages over a cross-sectional approach: it requires a lower number of subjects to reach a certain statistical power, and besides it being able to track the previously mentioned time-effect evolution on a group-by-group basis, it allows to determine the variability of the response within subjects [@guo2013; @fitzmaurice2012]. In other words,a longitudinal study permits to quantify how the variable changes within each subject across time.

Traditionally, a “frequentist” approach is used in biomedical research to derive inferences from the results of a longitudinal study. Such statistical view derives its name from the fact that it regards probability as a limiting frequency [wagenmakers2008] and its application is based on a null hypothesis test using the _analysis of variance over repeated measures_ (repeated measures ANOVA or rm-ANOVA). This methodology makes two key assumptions regarding longitudinal data: a constant correlation exists across same-subject measurements, and observations from each subject are obtained at all time points through the study  [@schober2018;@gueorguieva2004]. 

However, constant correlation is frequently unjustified as its value tends to diminish between measures when the time interval between them increases [@ugrinowitsch2004], and the violation of this assumption increases the false positivity rate [@lane2016].
Moreover, it is unlikely that complete observations in all subjects are obtained in a biomedical study due to reasons that can be specific to different situations. In a clinical trial, voluntary withdrawal from one or multiple patients can occur, whereas attrition in animals due to injury or weight loss can occur in preclinical experiments, and in both cases it is possible that unexpected complications with equipment or supplies arise, preventing the researcher from collecting measurements at a certain time point. 

When the aforementioned issues arise, rm-ANOVA requires exclusion of all subjects with missing observations from the analysis, thereby increasing costs for the study if the desired statistical power is not met with the remaining observations as it makes necessary to enroll more subjects [@ma2012]; and  raising the possibility that the rejection of those partial observations limits the demonstration of significant differences between groups. Additionally, rm-ANOVA uses a _post hoc_ analysis to assess the relevance between the measured response in different groups. This analysis is based on multiple repeated comparisons to estimate a _p-value_, a metric that is widely used as a measure of significance. Because the p-value is highly variable [@halsey2015;@nuzzo2014], multiple comparisons can inflate the false positivity rate [@liu2010],consequently biasing the conclusions of the study.

During the last decade, the biomedical community has started to recognize the limitations of a rm-ANOVA approach in the analysis of longitudinal information. This is exemplified by the use of  linear mixed effects models (LMEMs)  in certain groups to analyze tumor longitudinal data [@skala2010;@vishwanath2009]. Briefly, these models incorporate _fixed effects_, which correspond to the levels of experimental factors in the study (e.g. the different drug regimens in a clinical trial), and _random effects_, which account for random variation within the population [@pinheiro2006].These models are more flexible than rm-ANOVA as they can accommodate missing observations for multiple subjects, and allow different modeling strategies for the variability within each measure in every subject [@west2014;@pinheiro2006].On the other hand, they impose restrictions in the distribution of the errors of the model and random effects [@gueorguieva2004;@schielzeth2020].

Additionally, another assumption made in both rm-ANOVA and LMEMs models is that a linear relationship exists between the observed response and the explanatory variables (covariates) across the study [@pinheiro2006].This common assumption to both rm-ANOVA and LMEMs causes the models to be restrictive in their inferences when used in longitudinal data that does not follow a linear trend. In biomedical research, this particular behavior in longitudinal has been reported in studies of tumor response to radio/chemotherapy in preclinical and clinical settings[@vishwanath2009; @roblyer2011;@tank2020;@skala2010;@demidov2018], and wound healing and metabolism[@jones2018;@grice2010;@young1994]. These studies have shown that that the collected signal does not follow a linear trend over time, and presents high variability at different time points, making the estimations of a LMEM or rm-ANOVA model inconsistent with the pattern of the observed variations. Additionally,  although it is possible that a _post hoc_ analysis is able to find “significant” results ( _p_<0.05) by using multiple comparisons between the model terms, this metric is inherently biased due to the discrepancy between the data and the model.

As  the “frequentist” rm-ANOVA and the more advanced LMEM approach are both limited in the analysis of non-linear longitudinal information, there is a need for biomedical researchers to explore the use of additional statistical tools that allow the data (and not an assumed distribution) to determine the fit of the model while enabling inferences that are both adequate and consistent from a statistical perspective. 

Generalized additive models (GAMs) are a subset of generalized linear models that use _smooth functions_ (hencefort _smooths_) to estimate the parameters of a model. They have been used in palaeolimnology, ecology and clinical studies to model longitudinal data [@woolway2016;@hefley2017;@ko2007]. Briefly, GAMs use a combination of multiple functions (basis functions) to construct the smooths of the model [@wood2017]. Their main advantage over LMEMs and rm-ANOVA is that the model specification is directed by the _smooths_ rather than by a parametric relationship. This allows a consistent fit of the model with the data, and estimations of significance using the terms of the model. However, certain assumptions about the data are necessary: a normal distribution and constant variance of the residuals with the mean response. Therefore, GAMs provide a more suitable statistical method to analyze biomedical longitudinal data, when these assumptions of the model are met by the data.


However, it is possible that the assumptions of GAMs for longitudinal data do not hold under  certain circumstances. In that case, the field of _Bayesian statistics_ represents a relatively new area of Statistics that does not rely on _p-values_ and hypothesis tests to analyze information. Bayesian statistics can work with missing observations, allow the data (and not an underlying assumed distribution) to determine significant differences and are able to expand the number of comparisons and inferences derived form the analysis. On the other hand, the shift that Bayesian statistics represent from the traditional "frequentist" statistical view in research, the computational tools required for its implementation, and the underlying mathematical theory have limited the use of this approach in the biomedical research community. However,Bayesian theory is intuitive and shares some principles with "frequentist" statistics, and there is an increasing use and recognition of the advantages of their use across different areas of biomedical research such as clinical trial design and imaging[@biswas2009;@kelter2020;@kwon2020;@zhou2017]. 

Additionally,the current development in computational tools, specifically the programming language $\textsf{R}$, enable a rapid implementation of GAMs and Bayesian models for longitudinal data.In particular, $\textsf{R}$ has an extensive collection of documentation, functions and libraries that speed up the initial stages of the analsys and that enable the use of complex statistical methods without requiring a specialized set of programming skills from the user.

Therefore, this study focuses in three areas in the analysis of longitudinal data from a biomedical perspective. First, it presents the limitations of (rm-ANOVA) and LMEMs over longitudinal data, and explains how these limitations in turn affect the results of the analysis. Secondly, it uses $\textsf{R}$ to simulate non-linear longitudinal data following previously reported values in the literature, and presents the implementation of GAMs as a statistical tool for longitudinal data. And finally, it introduces Bayesian statistics and presents their implementation with GAMs to demonstrate the differences and benefits of this approach. with an emphasis in reproducibility  by providing the code, simulated dataset and a step-by-step guide of the computational implementation of different models, this study aims to encourage the exploration of modern statistical methods for biomedical longitudinal data, and to improve the  statistical standards in biomedical research.

- Why LMEMs are better than ANOVA

- How LMEMs (using splines) and a Bayesian analysis can be used to analyze longitudinal data


https://www.frontiersin.org/articles/10.3389/fevo.2018.00149/full

```{r,FIGURE 1,echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Simulated longitudinal data with a linear trend.'}
rm(list=ls())
set.seed(123)
library(ggplot2)
library(splines)
library(tidyverse)
library(here)


linear<-read.csv(here("data","Simulated_linear.csv"))

sim_linear <- function(dat, n = 10, sd = 5) {
    linear_vals <- dat %>%
        slice(rep(1:n(), each = n)) %>%
        group_by(Group,Day) %>%
        mutate(observation = rnorm(n, y, sd)) %>%
        ungroup()

    return(linear_vals)
}
n<-10
sd<-2
linear_vals <- sim_linear(linear, n, sd)
linear_vals[] <- lapply(linear_vals, function(observation) ifelse(observation<=0, NA, observation)) #taking out values below 0

 ggplot(linear_vals, aes(x = Day, y = observation, color = Group)) +
    geom_point() +
    ggtitle("Simulated linear time-varying responses") +
    scale_color_viridis_d(end = 0.75) +
    geom_line(aes(y = y), alpha = 0.75) +
    theme_bw()

```

## Section 1: 

### Challenges presented by longitudinal studies: 

### 1 The "frequentist" case for longitudinal data

The _repeated measures analysis of variance_ (rm-ANOVA) is the standard for the statistical analysis of longitudinal data, and there are key assumptions that are made in order to make the model valid. From a practical view, they can be divided in three areas: linear relationship between covariates and response, constant correlation between measurements, and complete observations for all subjects. Each one of these assumptions is discussed below.
  
#### 1.1 Linear relationship 

In a biomedical longitudinal study, two or more groups of subjects (humans, mice, samples) are subject to a different treatments (e.g. group of mice receiving a novel drug vs. a group that receives a placebo), and measurements from each subject within each group are collected at specific time points. Moreover, it is assumed that the collected response has two components: a _fixed_ and a _random_ component. The _fixed_ component can be understood as a constant value in the response which the researcher intends to measure, i.e, the effect of a novel drug in a subject.The _random_ component can be defined as "noise" caused by some some factors that are not of interest to the researcher, i.e., if the concentration of a drug is measured in some subjects within the same group in the early hours of the morning while others are measured in the afternoon, the researcher might consider this variability in the collection time of the measurement to introduce some "noise" in the signal. As their name suggests, this "random" variabliity needs to be modeled as a variable rather than as a constant value.


Mathematically speaking, if a normally distributed response $y$ is measured repeatedly at $t$ time points from subjects in $p$ groups, where each group has a certain $n_p$ number of subjects, the the model for the response $y_{hij}$ becomes:

\begin{equation}
\label{eq:ANOVA}
$$y_{kit}=\mu+\gamma_k+\tau_t+(\gamma \tau)_{kt}+\pi_{i(k)}+e_{kit}$$
\end{equation}


Where 

$i=1,...,n_K$ $t=1,...,T$, $k=1,...,K$; with $\pi_i{h} \sim N(0,\sigma^{2}_\epsilon)$ (independently normally distributed) and $e_{hij} \sim N(0,\sigma^{2}_\epsilon)$

In this model, $\mu$ represents the group mean, $\gamma_h$ is the _fixed effect_ of group $h$, $\tau_j$ is the fixed effect of time $j$, and $(\gamma \tau)_{hj}$ represents the interaction of time and group effects. The term $\pi_{ij}$ represents the _random effects_ for each subject within each group.Finally, $e_{hij}$ represents the independent random error terms, which need to be normally distributed with mean 0 [@davis2002]. The model then, is a linear combination of terms, and if plotted, represents a line. 

_Question: How can one make a plot that tests the "limits" of the model, i.e how much "wiggliness" can this model accomodate? Make a plot to show the behavior of the model_



#### 1.2 Covariance in rm-ANOVA and LMEMs

In a longitudinal study there is an expected _variance_ between repeated measurements on the same subject, and since repeated measures are also taken on the rest of the subjects within each group, there is a _covariance_ between  measurements at each time point within each group. The _covariance matrix_ (also known as the variance-covariance matrix) is a matrix that captures the variation between and within subjects in a longitudinal study[@wolfinger1996] (For an in-depth analysis of the covariance matrix see [@west2014;@weiss2005]). 

For practical purposes, an rm-ANOVA analysis assumes that the covariance matrix has a specific construction known as _compound symmetry_ (also known as "sphericity" or "circularity"). Under this assumption, the between-subject variance and within-subject correlation  are constant across time [@weiss2005;@geisser1958;@huynh1976]. However, it has been shown that this condition is frequently unjustified because the correlation between measurements tends to change over time [@maxwell2017]; and it is higher between consecutive measurements [@gueorguieva2004;@ugrinowitsch2004].When the data violates the sphericity assumption, the false positivity rate is inflated [@haverkamp2017].

In the case of LMEMs, one of their main advantages is that they allow multiple structures for the variance-covariance matrix including exponential, autoregressive of order 1, rational quadratic and others[@pinheiro2006]. The choice for the covariance matrix needs to be carefully considered by the investigator based on the analyzing the collected data.


*make plot that explains between and within correlation*

#### 1.3 Missing observations

Missing observations are an issue that arises frequently in longitudinal studies. In biomedical research, this situation can be caused by reasons beyond the control of the investigator [molenberghs2004].Dropout from patients, or attrition or injury in animals are among the reasons for missing observations. Statistically, missing information can be classified as _missing at random_ (MAR), _missing completely at random_ (MCAR), and _missing not at random_ (MNAR) [@weiss2005].  In a MAR scenario, the pattern of the missing information is related to some variable in the dataset, but it is not related to the variable of interest [@scheffer2002]. If the data are MCAR, this means that the missigness is completely unrelated to the collected information [@potthoff2006], and in the case of MNAR the missing values are dependent on their value. An rm-ANOVA model assumes complete observations for all subjects, and therefore subjects with one or more missing observations are excluded from the analysis. This is inconvenient because the remaining subjects might not accurately represent the population, and statistical power is affected by this reduction in sample size [@ma2012].

In the case of LMEMs, one key advantage over rm-ANOVA is that inferences from the model are valid when missing observations in the dataset exist that are MAR [@west2014]. The pattern of missing observations can be considered MAR if the missing observations are not related any of the other variables measured in the study [@maxwell2017]. For example, if attrition occurs in all mice that had lower weights at the beginning of a chemotherapy response study. Because in this case the missigness is unrelated to other variables of interest, the missing data can be considered MAR. 

This section has presented the limitations of rm-ANOVA to analyze longitudinal information and the differences of LMEMs with regards to missing data and the modeling of the covariance matrix. Of notice, LMEMs offer a more robust and flexible approach than rm-ANOVA and if the data follows a linear trend, they provide an excellent choice to derive inferences from a repeated measures study. However, when the data presents high variability, LMEMs fail to capture the non-linear trend of the data. To analyze such type of data, we propose the use of generalized additive models (GAMs) in the following section.

#### 2 GAMs as a special case of Generalized Linear Models:

A GAM is a special case of the Generalized Linear Model (GLM), a framework that allows for response distributions that do not follow a normal distribution [@wood2017;@hastie1987].  [@simpson2018].  To allow more flexibility, GAMs use _smooth functions_  to model the relationship between the covariates and the response. The smooth functions are represented using splines over  evenly spaced ranges of the covariates known as _knots_.  A GAM model can be represented as:


\begin{equation}
(\#eq:labelGAM)
y_{t}=\beta_0+f(x_t)+\epsilon_t  
\end{equation}

Where $y_t$ is the response at time $t$, $\beta_0$ is the expected value at time 0, the change of $y$ over time is represented by the function $f(x_t)$ and $\epsilon_t$ represents the residuals.

*This equation above does not have an "interaction term" similar to that of anova.*

This model is similar in its construction to that of \ref{eq:ANOVA}, but the key difference relies on the fact that instead of a linear relationship for the covariates, a function is used. 

#### 1.3 Bayesian brief introduction, and compare the results of 1.2 to the results of Bayesian


* Section 2: Implementation of both LMEMs and Bayesian and their results


Present the implementation of a spline-fitted model in R, using data simulated from [@vishwanath2009]

***



# References
