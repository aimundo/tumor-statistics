---
title: '**Bayesian statistics for longitudinal studies in biomedical research**'
author: 
- Ariel Mundo^[Department of Biomedical Engineering, University of Arkansas, Fayetteville]
- Timothy J. Muldoon^[Department of Biomedical Engineering, University of Arkansas, Fayetteville]
- John R. Tipton^[Department of Mathematical Sciences, University of Arkansas, Fayetteville]
  
bibliography: refs.bib
output:
  pdf_document: 
    fig_caption: yes
  html_document: default
  css: style.css
  word_document:
    reference_docx: docx_template.docx
mainfont: Times New Roman
link-citations: yes
subtitle: '_Their application and use in biomedical research_'
biblio-style: apalike
---



## Paper outline
<span style="color: red;">\textcolor{red}{The paper Introduction has been updated, proposed sections appear at the end of the document as well as an initial graph.}</span>


## Background

A longitudinal study is defined as that which is designed to repeatedly measure a variable of interest in a group (or groups) of subjects. In biomedical research, this type of study arises when the investigator intends to observe the evolution of the effect of a certain treatment across time, rather than analyzing it at a single time point (a cross-sectional study). Clinical examples of this  approach in biomedical research include studies on breast and neck cancer[@sio2016;@kamstra2015]; in the first case, weekly measurements of skin toxicities in  patients with radiation-induced dermatitis were taken for up to 8 weeks; whereas in the latter mouth opening was assessed at 6,12, 18, 24 and 36 months after radiotherapy (RT). Longitudinal studies have used also to measure tumor response [@roblyer2011;@tank2020;@pavlov2018;@demidov2018], antibody expression[@ritter2001;@roth2017], and cell metabolism[@jones2018;@skala2010]. From a statistical standpoint, a longitudinal study presents advantages over a cross-sectional approach:it requires a lower number of subjects to reach a certain statistical power, and besides it being able to track the previously mentioned time-effect evolution on a group-by-group basis, it allows to determine the variability of the response within subjects [@guo2013; @fitzmaurice2012]. In other words,a longitudinal study permits to quantify how the variable changes within each subject across time.

Traditionally, a “frequentist” approach is used in biomedical research to derive inferences from the results of a longitudinal study. Such statistical view derives its name from the fact that it regards probability as a limiting frequency [wagenmakers2008] and its application is based on a null hypothesis test using the _analysis of variance over repeated measures_ (repeated measures ANOVA or rm-ANOVA). This methodology makes two key assumptions regarding longitudinal data: a constant correlation exists across same-subject measurements, and observations from each subject are obtained at all time points through the study  [@schober2018;@gueorguieva2004]. 

However, constant correlation is frequently unjustified as its value tends to diminish between measures when the time interval between them increases[@ugrinowitsch2004], and the violation of this assumption increases the false positivity rate [@lane2016].
Moreover, it is unlikely that complete observations in all subjects are obtained in a biomedical study due to reasons that can be specific to different situations. In a clinical trial, voluntary withdrawal from one or multiple patients can occur, whereas attrition in animals due to injury or weight loss can occur in preclinical experiments, and in both cases it is possible that unexpected complications with equipment or supplies arise, preventing the researcher from collecting measurements at a certain time point. 

When the aforementioned issues arise, rm-ANOVA requires to exclude all subjects with missing observations from the analysis, thereby increasing costs for the study if the desired statistical power is not met with the remaining observations as it makes necessary to enroll more subjects; and  raising the possibility that the rejection of those partial observations limits the demonstration of significant differences between groups. Additionally, rm-ANOVA uses a _post hoc_ analysis to assess the relevance between the measured response in different groups. This analysis is based on multiple repeated comparisons to estimate a _p-value_, a metric that is widely used as a measure of significance. Because the p-value is highly variable [@halsey2015;@nuzzo2014], multiple comparisons can inflate the false positivity rate [@liu2010],consequently biasing the conclusions of the study.

During the last decade, the biomedical community has started to recognize the limitations of a rm-ANOVA approach in the analysis of longitudinal information. This is exemplified by the pioneering use of  linear mixed effects models (LMEMs)  in certain groups to analyze tumor longitudinal data [@skala2010;@vishwanath2009]. Briefly, these models incorporate _fixed effects_, which correspond to the levels of experimental factors in the study (e.g. the different drug regimens in a clinical trial), and _random effects_, which account for random variation within the population [@pinheiro2006].These models are more flexible than rm-ANOVA as they can accommodate missing observations for multiple subjects, and allow different modeling strategies for the variability within each measure in every subject [@west2014;@pinheiro2006].On the other hand, they impose restrictions in the distribution of the errors of the model and random effects [@gueorguieva2004;@schielzeth2020].

Additionally, another assumption is made in both rm-ANOVA and LMEMs models, where a linear relationship is expected between the observed response and the covariates across the study [@pinheiro2006].This common assumption to both rm-ANOVA and LMEMs causes the models to be restrictive in their inferences when used in longitudinal data that does not follow a linear trend. In biomedical research, this particular behavior in longitudinal has been reported in studies of tumor response to radio/chemotherapy in preclinical and clinical settings[@vishwanath2009; @roblyer2011;@tank2020;@skala2010;@demidov2018], and wound healing and metabolism[@jones2018;@grice2010;@young1994]. This studies have shown that that the collected signal does not follow a linear trend over time, and presents high variability at different time points, making the estimations of a LMEM or rm-ANOVA model inconsistent with the pattern of the observed variations. Additionally,  although it is possible that a post hoc analysis is able to find “significance”( _p-value_<0.05) by using multiple comparisons between the model terms, this estimator would be inherently biased because of the lack of fit between the information and the model.

As  the “frequentist” rm-ANOVA and the more advanced LMEM approach are both limited in the analysis of non-linear longitudinal information, there is a need for biomedical researchers to explore the use of additional statistical tools that allow the information (and not an assumed distribution) to determine the fit of the model while enabling inferences that are both adequate and consistent from a statistical perspective. 

Generalized additive models (GAMs) are a subset of generalized linear models that use _smooth functions_ (hencefort _smooths_) to estimate the parameters of a model. They have been used in palaeolimnology, ecology and clinical studies to model longitudinal data[@woolway2016;@hefley2017;@ko2007]. Briefly, GAMs use a combination of multiple functions (basis functions)to construct the smooths of the model [@wood2017]. Their main advantage over LMEMs and rm-ANOVA is that the model specification is directed by the _smooths_ rather than by a parametric relationship. This allows a consistent fit of the model with the data, and estimations of significance using the terms of the model. However, certain assumptions about the data are necessary: a normal distribution and constant variance of the residuals with the mean response. Therefore, GAMs provide a more suitable statistical method to analyze biomedical longitudinal data, when these assumptions of the model are met by the data.


However, it is possible that the assumptions of GAMs for longitudinal data do not hold under  certain circumstances. In that case, the field of _Bayesian statistics_ represents a relatively new area of Statistics that does not rely on _p-values_ and hypothesis tests to analyze information. Bayesian statistics can work with missing observations, allow the data (and not an underlying assumed distribution) to determine the outcome in regard to significance and are able to expand the number of comparisons and inferences derived form the analysis. On the other hand, the shift that Bayesian statistics represent from the traditional "frequentist" statistical view in research, the computational tools required for its implementation, and the underlying mathematical theory have limited the use of this approach in the biomedical research community. However,Bayesian theory is intuitive and shares some principles with "frequentist" statistics, and there is an increasing use and recognition of the advantages of their use across different areas of biomedical research such as clinical trial design and imaging[@biswas2009;@kelter2020;@kwon2020;@zhou2017]. 

Additionally,the current development in computational tools, specifically the programming language $\textsf{R}$, enable a rapid implementation of GAMs and Bayesian models for longitudinal data.In particular, $\textsf{R}$ has an extensive collection of documentation, functions and libraries that speed up the initial stages of the analsys and that enable the use of complex statistical methods without requiring a specialized set of programming skills from the user.

Therefore, this study focuses in three areas in the analysis of longitudinal data from a biomedical perspective. First, it presents the limitations of (rm-ANOVA) and LMEMs over longitudinal data, and explains how these limitations in turn affect the results of the analysis. Secondly, it uses $\textsf{R}$ to simulate non-linear longitudinal data following previously reported values in the literature, and presents the implementation of GAMs as a statistical tool for longitudinal data. And finally, it introduces Bayesian statistics and presents their implementation with GAMs to demonstrate the differences and benefits of this approach. with an emphasis in reproducibility  by providing the code, simulated dataset and a step-by-step guide of the computational implementation of different models, this study aims to encourage the exploration of modern statistical methods for biomedical longitudinal data, and to improve the  statistical standards in biomedical research.

- Why LMEMs are better than ANOVA

- How LMEMs (using splines) and a Bayesian analysis can be used to analyze longitudinal data


https://www.frontiersin.org/articles/10.3389/fevo.2018.00149/full

```{r,FIGURE 1,echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Simulated longitudinal data with a linear trend.'}
rm(list=ls())
set.seed(123)
library(ggplot2)
library(splines)
library(tidyverse)
library(here)


linear<-read.csv(here("data","Simulated_linear.csv"))

sim_linear <- function(dat, n = 10, sd = 5) {
    linear_vals <- dat %>%
        slice(rep(1:n(), each = n)) %>%
        group_by(Group,Day) %>%
        mutate(observation = rnorm(n, y, sd)) %>%
        ungroup()

    return(linear_vals)
}
n<-10
sd<-2
linear_vals <- sim_linear(linear, n, sd)
linear_vals[] <- lapply(linear_vals, function(observation) ifelse(observation<=0, NA, observation)) #taking out values below 0

 ggplot(linear_vals, aes(x = Day, y = observation, color = Group)) +
    geom_point() +
    ggtitle("Simulated linear time-varying responses") +
    scale_color_viridis_d(end = 0.75) +
    geom_line(aes(y = y), alpha = 0.75) +
    theme_bw()

```

## Section 1: 

### Challenges presented by longitudinal studies: 

### 1 The "frequentist" case for longitudinal data

The _repeated measures analysis of variance_ (rm-ANOVA) is the standard for the statistical analysis of longitudinal data, and there are key assumptions that are made in order to make the model valid. From a practical view, they can be divided in three areas: linear relationship between covariates and response, constant correlation between measurements, and complete observations for all subjects. Each one of these assumptions is discussed below.
  
#### 1.1 Linear relationship 

In a biomedical longitudinal study, two or more groups of subjects (humans, mice, samples) are subject to a different treatments (e.g. group of mice receiving a novel drug vs. a group that receives a placebo), and measurements from each subject within each group are collected at specific time points. Moreover, it is assumed that the collected response has two components: a _fixed_ and a _random_ component. The _fixed_ component can be understood as a constant value in the response which the researcher intends to measure, i.e, the effect of a novel drug in a subject.The _random_ component can be defined as "noise" caused by some some factors that are not of interest to the researcher, i.e., if the concentration of a drug is measured in some subjects within the same group in the early hours of the morning while others are measured in the afternoon, the researcher might consider this variability in the collection time of the measurement to introduce some "noise" in the signal. As their name suggests, this "random" variabliity needs to be modeled as a variable rather than as a constant value.


Mathematically speaking, if a normally distributed response $y$ is measured repeatedly at $t$ time points from subjects in $p$ groups, where each group has a certain $n_p$ number of subjects, the the model for the response $y_{hij}$ becomes:

\begin{equation}
(\#eq:labelANOVA)
y_{hij}=\mu+\gamma_h+\tau_j+(\gamma \tau)_{hj}+\pi_{i(h)}+e_{hij}
\end{equation}


Where 

$i=1,...,n_h$ $j=1,...,t$, $h=1,...,p$; with $\pi_i{h} \sim N(0,\sigma^{2}_\epsilon)$ (independently normally distributed) and $e_{hij} \sim N(0,\sigma^{2}_\epsilon)$

In this model, $\mu$ represents the group mean, $\gamma_h$ is the _fixed effect_ of group $h$, $\tau_j$ is the fixed effect of time $j$, and $(\gamma \tau)_{hj}$ represents the interaction of time and group effects. The term $\pi_{ij}$ represents the _random effects_ for each subject within each group.Finally, $e_{hij}$ represents the independent random error terms, which need to be normally distributed with mean 0 [@davis2002]. The model then, is a linear combination of terms, and if plotted, it would a straight line. 

_Question: How can one make a plot that tests the "limits" of the model, i.e how much "wiggliness" can this model accomodate? Make a plot to show the behavior of the model_

#### 1.2 Covariance and correlation in rm-ANOVA and LMEMs

In a longitudinal study, the fact that multiple measures are taken on the same subject creates a a _covariance_ issue that needs to be incorporated into the model. Specifically, a parametric model (rm-ANOVA or LMEMs) assumes that there is no relationship between the repeated measures of different subjects (no correlation), but that there is a relationship for the repeated measures of the same subject. The latter is then taken in to account by a _covariance_ structure [@wolfinger1996].  In this case, _covariance_ can be defined as the dependency  between two different values, e.g. if higher values of a variable correspond with higher values of another value, the covariance is positive.  Although not immediately apparent, the reason for this specification arises from the fact that the model from \@ref(eq:labelANOVA) is re-written in matrix form for computational purposes (For an in-depth analysis see [@west2014;@weiss2005]). 

For an rm-ANOVA analysis, the _variance-covariance matrix_ or the matrix that specifies the relationships between the different repeated measures, needs to have a specific construction known as _compound symmetry_ (which is commonly known also as "sphericity" or "circularity"). This assumes that variance of observations and the correlation between observations are constant,and when this is not the case, adjustments need to be made  [@weiss2005;@geisser1958;@huynh1976].However, it has been shown when the data violates the sphericity assumption, the false positivity rate is inflated [@haverkamp2017].This assumption is frequently unjustified as the correlation between measurements tends to change over time; and it is higher between consecutive measurements [@gueorguieva2004;@ugrinowitsch2004].

In the case of LMEMs, they have the advantage of allowing different structures of the variance-covariance matrix [@pinheiro2006]. 


*make plot that explains between and within correlation*

#### 1.3 Missing observations

In a longitudinal study, missing observations are an important issue that arises frequently. In biomedical research, this situation is not unusual and can be caused by different reasons in the context of each study, but they are typically beyond the control of the investigator [molenberghs2004].statistical treatment of missing observations is particularly important for longitudinal studies. 
*talk about missing at random, mcar etc*


One of the key assumptions for rm-ANOVA is the constant correlation among measurements. This frequently not the case as the correlation reduces as the time interval between two measurements increases []. From a practical  

#### 1.2 the case of GMEMs using splines and how they work and how they are better than rm-ANOVA



#### 1.3 Bayesian brief introduction, and compare the results of 1.2 to the results of Bayesian


* Section 2: Implementation of both LMEMs and Bayesian and their results


Present the implementation of a spline-fitted model in R, using data simulated from [@vishwanath2009]

***



# References
